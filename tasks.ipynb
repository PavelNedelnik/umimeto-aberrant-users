{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from typing import Optional, Iterable, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.load_scripts import load_ipython_item, load_ipython_log\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "\n",
    "item = load_ipython_item(data_path)\n",
    "log, features = load_ipython_log(data_path, data_path / \"edulint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def find_example_message_from_message_code(messages, message_code):\n",
    "    pattern = r'\"[^\"]*{}[^\"]*\"'.format(re.escape(message_code))\n",
    "    message = re.search(pattern, messages)\n",
    "    if message is None:\n",
    "        return f'\"{message_code}_unknown\"'\n",
    "    return message.group()\n",
    "\n",
    "\n",
    "with open(data_path / \"edulint\" / \"results.txt\") as f:\n",
    "    messages = f.read()\n",
    "    feature_descriptions = {}\n",
    "    for feature_name in features:\n",
    "        feature_descriptions[feature_name] = find_example_message_from_message_code(\n",
    "            messages, feature_name.upper()\n",
    "        )\n",
    "\n",
    "feature_descriptions['r1705'] = 'Unnecessary elif after return'\n",
    "feature_descriptions['c0103'] = 'Naming style violation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.DataFrame(\n",
    "    np.vstack(log[\"linter_messages\"]), columns=features, index=log.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_correlated = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_submission_for_messages(*message_codes: Iterable[str], idx: Optional[Union[int, Iterable[int]]]=0):\n",
    "    for code in message_codes:\n",
    "        print(f'Total: {messages[code].sum()}, Description: {feature_descriptions[code]}')\n",
    "    print('-------------------------------------------------------------')\n",
    "    mask = messages[message_codes[0]].copy()\n",
    "    if len(message_codes) > 1:\n",
    "        for code in message_codes[1:]:\n",
    "            if messages[code].dtype == bool:\n",
    "                mask &= messages[code]\n",
    "            else:\n",
    "                mask += messages[code]\n",
    "        print(f'Intersection total: {mask.sum()}')\n",
    "    print(log[mask > 0].iloc[idx][\"answer\"])\n",
    "\n",
    "example_submission_for_messages(\"w293\", 'e303', idx=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_task(name: Optional[str] = None, idx: Optional[int] = None):\n",
    "    if name is not None:\n",
    "        idx = item[item[\"name\"] == name].index[0]\n",
    "    if idx in item.index:\n",
    "        row = item.loc[idx]\n",
    "        print('Task: ', row['name'])\n",
    "        print('='*50)\n",
    "        print('Description: ', row['instructions'], sep='\\n')\n",
    "        print('-'*50)\n",
    "        print('Example solution: ', row['solution'], sep='\\n')\n",
    "    else:\n",
    "        print('Task not found!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_task('Super')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = messages.sum(axis=0).sort_values()\n",
    "fig = px.bar(x=[feature_descriptions[i] for i in counts.index], y=counts / counts.sum())\n",
    "fig.update_layout(\n",
    "    title=f\"Selected linter messages and the frequency of their presence (in total {counts.sum()} submissions)\",\n",
    "    xaxis_title=\"Message\",\n",
    "    yaxis_title=\"Frequency of submissions\",\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_correlations = messages.corr()\n",
    "\n",
    "fig = px.imshow(\n",
    "    feature_correlations,\n",
    "    labels=dict(x=\"Message codes\", y=\"Messages\", color=\"Correlation\"),\n",
    "    x=feature_correlations.columns,\n",
    "    y=feature_correlations.columns,\n",
    "    color_continuous_scale=\"Viridis\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title=\"Feature Correlogram Before Preprocessing\",\n",
    "    yaxis=dict(\n",
    "        tickvals=list(range(len(feature_correlations.columns))),\n",
    "        ticktext=[feature_descriptions[col] for col in feature_correlations.columns],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "feature_distances = 1 - np.abs(feature_correlations)\n",
    "dist_linkage = hierarchy.ward(squareform(feature_distances))\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=messages.columns.to_list(), leaf_rotation=90\n",
    ")\n",
    "plt.title('Dendrogram of Feature Correlations Before Preprocessing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_messages(description, *args):\n",
    "    new_name = '+'.join(args)\n",
    "    messages[new_name] = messages[args[0]].copy()\n",
    "    for arg in args[1:]:\n",
    "        if messages[arg].dtype == bool:\n",
    "            messages[new_name] |= messages[arg]\n",
    "        else:\n",
    "            messages[new_name] += messages[arg]\n",
    "    feature_descriptions[new_name] = description\n",
    "    messages.drop(list(args), axis=1, inplace=True)\n",
    "\n",
    "\n",
    "if combine_correlated:\n",
    "    combine_messages('Bad inline comment.', 'e261', 'e262')\n",
    "    combine_messages('Redefining var/foo.', 'f811', 'e0102')\n",
    "    combine_messages('Spaces in indentation.', 'e101', 'w191')\n",
    "    combine_messages('Bad indentation.', 'e111', 'e117')\n",
    "    combine_messages('No spacing between blocks.', 'e302', 'e305')\n",
    "    # E305 and E302 both show students debugging / trying to calculate the answer manually / very confused about the basic principles of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_correlations = messages.corr()\n",
    "feature_distances = 1 - np.abs(messages.corr())\n",
    "\n",
    "fig = px.imshow(\n",
    "    feature_correlations,\n",
    "    labels=dict(x=\"Messages\", y=\"Message codes\", color=\"Correlation\"),\n",
    "    x=feature_correlations.columns,\n",
    "    y=feature_correlations.columns,\n",
    "    color_continuous_scale=\"Viridis\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title=\"Feature Correlogram After Preprocessing\",\n",
    "    yaxis=dict(\n",
    "        tickvals=list(range(len(feature_correlations.columns))),\n",
    "        ticktext=[feature_descriptions[col] for col in feature_correlations.columns],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_distances = 1 - np.abs(feature_correlations)\n",
    "dist_linkage = hierarchy.ward(squareform(feature_distances))\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=messages.columns.to_list(), leaf_rotation=90\n",
    ")\n",
    "plt.title('Dendrogram of Feature Correlations After Preprocessing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How likely are users to repeat each of the detected mistakes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How severe are the messages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naively predicting whether the submission was unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "min_score = 0.02\n",
    "scores = {}\n",
    "for msg in messages.columns:\n",
    "    corr = matthews_corrcoef(messages[msg], 1 - log[\"correct\"])\n",
    "    if abs(corr) > min_score:\n",
    "        scores[msg] = corr\n",
    "\n",
    "labels, score = zip(*sorted(scores.items(), key=lambda x: x[1]))\n",
    "fig = px.bar(x=score, y=[feature_descriptions[label] for label in labels])\n",
    "fig.update_layout(\n",
    "    title=\"Correlation between the presence of each message and whether the submission was unsuccessful\",\n",
    "    xaxis_title=\"Messages\",\n",
    "    yaxis_title=\"MCC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_scores = pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import r_regression\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "r_scores = sorted(list(zip(messages.columns, r_regression(messages, log[\"correct\"]))),key=lambda x: x[1])\n",
    "plt.barh(*zip(*r_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "def pretty_confusion_matrix(cm):\n",
    "    labels = [\n",
    "        f\"{label}\\n{count}\"\n",
    "        for label, count in zip(\n",
    "            [\"True Negatives\", \"False Positives\", \"False Negatives\", \"True Positives\"],\n",
    "            [cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]],\n",
    "        )\n",
    "    ]\n",
    "    # Create confusion matrix table\n",
    "    cm_table = ff.create_annotated_heatmap(\n",
    "        z=cm,\n",
    "        x=[\"Predicted 0\", \"Predicted 1\"],\n",
    "        y=[\"Actual 0\", \"Actual 1\"],\n",
    "        colorscale=\"Blues\",\n",
    "    )\n",
    "    cm_table.update_layout(\n",
    "        title_text=\"Confusion Matrix\",\n",
    "        xaxis=dict(title=\"Predicted label\"),\n",
    "        yaxis=dict(title=\"True label\"),\n",
    "    )\n",
    "\n",
    "    # Add labels to the confusion matrix\n",
    "    for i in range(len(cm_table.layout.annotations)):\n",
    "        cm_table.layout.annotations[i].text = labels[i]\n",
    "\n",
    "    # Show confusion matrix\n",
    "    cm_table.show()\n",
    "\n",
    "\n",
    "def confusion_matrix_for_message(code):\n",
    "    cm = confusion_matrix(log[\"correct\"], messages[code])\n",
    "    pretty_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    messages, 1 - log[\"correct\"], test_size=0.33, random_state=42\n",
    ")\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "scores = np.round(cross_val_score(clf, X_train, y_train, cv=5, scoring=\"matthews_corrcoef\"), 3)\n",
    "print(f\"Scores on validation data for each fold: {scores}.\")\n",
    "print(f\"Score on the holdout test set: {matthews_corrcoef(y_test, clf.predict(X_test))}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "print('Precision: ', precision_score(y_test, pred))\n",
    "print('Recall: ', recall_score(y_test, pred))\n",
    "pretty_confusion_matrix(confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "importance = permutation_importance(clf, X_test, y_test, scoring=\"matthews_corrcoef\", random_state=42)\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(len(messages.columns)):\n",
    "    if importance.importances_mean[i] > 0.003:\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=importance.importances[i],\n",
    "                name=feature_descriptions[messages.columns[i]],\n",
    "                hoverinfo='name',\n",
    "                hoverlabel = dict(namelength = -1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Permutation Feature Importance for a Model Trained to Predict the Success of a Submission from the presence of Linter Messages\",\n",
    "    yaxis_title=\"Features\",\n",
    "    xaxis_title=\"Importance\",\n",
    "    showlegend=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is there positive correlation for some of the messages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of session is defined as sucessful submission, changing to a different task or not submitting for more than 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log = []\n",
    "for user in np.unique(log['user']):\n",
    "    # get the user history and make sure the values are sorted\n",
    "    user_history = log[log['user'] == user].sort_values('time')\n",
    "\n",
    "    # find the session breakpoints\n",
    "    user_history['sessionEnd'] = user_history['correct']        | \\\n",
    "        user_history['item'].ne(user_history['item'].shift(-1)) | \\\n",
    "        (user_history['time'].diff() > pd.Timedelta(minutes=20))\n",
    "\n",
    "    # propagate the session success backwards\n",
    "    user_history['sessionSucess'] = False # to correctly initialize the type\n",
    "    for index, row in user_history.iloc[::-1].iterrows():\n",
    "        if row['sessionEnd']:\n",
    "            sucess = row['correct']\n",
    "        user_history.at[index, 'sessionSucess'] = sucess\n",
    "    new_log.append(user_history)\n",
    "\n",
    "log = pd.concat(new_log).sort_index()\n",
    "messages.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the success of the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if messages.dtypes.apply(lambda x: x == bool).all():\n",
    "    msg_scores = {}\n",
    "    for msg in messages.columns:\n",
    "        msg_scores[feature_descriptions[msg]] = matthews_corrcoef(messages[msg], 1 - log[\"sessionSucess\"])\n",
    "\n",
    "    x, y = zip(*sorted(msg_scores.items(), key=lambda x: x[1]))\n",
    "    fig = px.bar(x=x, y=y)\n",
    "    fig.update_layout(\n",
    "        title=\"Correlation between the presence of each message and whether the session was unsuccessful\",\n",
    "        xaxis_title=\"Messages\",\n",
    "        yaxis_title=\"MCC\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import r_regression\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "min_score = 0.01\n",
    "\n",
    "r_scores = sorted(\n",
    "    [\n",
    "        tup for tup in zip(\n",
    "            messages.columns,\n",
    "            r_regression(messages, log[\"sessionSucess\"])\n",
    "        ) if abs(tup[1]) > min_score\n",
    "    ],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "plt.barh(*zip(*r_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages = messages[messages.columns[np.asarray(list(msg_scores.values())) > 0.01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    messages, 1 - log[\"sessionSucess\"], test_size=0.33, random_state=0\n",
    ")\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "scores = np.round(cross_val_score(clf, X_train, y_train, cv=5, scoring=\"matthews_corrcoef\"), 3)\n",
    "print(f\"Scores on validation data for each fold: {scores}.\")\n",
    "print(f\"Score on the holdout test set: {matthews_corrcoef(y_test, clf.predict(X_test))}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "print('Precision: ', precision_score(y_test, pred))\n",
    "print('Recall: ', recall_score(y_test, pred))\n",
    "pretty_confusion_matrix(confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at only last N submissions is a session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time until completion / the next submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at sudents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the messages distinguish successful students from unsuccessful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "cutoff = 1000\n",
    "max_label_len = 35\n",
    "max_labels = 10\n",
    "total_labels = 25\n",
    "min_support = 20\n",
    "\n",
    "# groupby item\n",
    "frequencies = []\n",
    "supports = []\n",
    "index = []\n",
    "for value, count in log['item'].value_counts().items():\n",
    "    if count > cutoff:\n",
    "        # calculate the support of each message\n",
    "        supports.append(messages[log['item'] == value].sum(axis=0))\n",
    "        # calculate the frequency of each message\n",
    "        frequencies.append(messages[log['item'] == value].mean(axis=0).apply(lambda x: entropy([x, 1-x], base=2)))\n",
    "        index.append(value)\n",
    "\n",
    "# combine into a dataframe\n",
    "frequencies = pd.DataFrame(\n",
    "    np.vstack(frequencies),\n",
    "    index=[item.loc[i]['name'] for i in index],\n",
    "    columns=messages.columns\n",
    ").T\n",
    "\n",
    "supports = pd.DataFrame(\n",
    "    np.vstack(supports),\n",
    "    index=[item.loc[i]['name'] for i in index],\n",
    "    columns=messages.columns\n",
    ").T\n",
    "\n",
    "frequencies[supports < min_support] = np.nan\n",
    "\n",
    "# calculate the total frequencies for each message\n",
    "frequencies['Total Frequency'] = messages.mean(axis=0)\n",
    "\n",
    "# highlight messages based on their correlation with failure of the submission\n",
    "best_pos_labels = correlation_scores.sort_values(ascending=False)[:max_labels//2].index\n",
    "best_neg_labels = correlation_scores.sort_values()[:max_labels//2].index\n",
    "most_frequent_labels = frequencies['Total Frequency'].sort_values(ascending=False)[:max_labels].index\n",
    "\n",
    "filtered = list(set(best_pos_labels) | set(best_neg_labels) | set(most_frequent_labels))\n",
    "filtered_index = frequencies.loc[filtered].sort_values(by='Total Frequency', ascending=False).index\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(15,8)})\n",
    "g = sns.heatmap(\n",
    "    frequencies.loc[filtered_index],  # sort and pick by mean entropy\n",
    "    vmin=0, vmax=1,\n",
    "    yticklabels=[feature_descriptions[idx][:max_label_len] for idx in filtered],  # shorten the descriptions\n",
    "    mask=frequencies.loc[filtered_index].isnull(),\n",
    "    cmap=sns.cm.rocket_r\n",
    ").set_title(f'Frequency of Linter Messages for the Most Frequent Tasks With Min Support of {min_support}.')\n",
    "\n",
    "for tick_label in g.axes.get_yticklabels():\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in most_frequent_labels]:\n",
    "        tick_label.set_color(\"green\")\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in best_pos_labels]:\n",
    "        tick_label.set_color(\"red\")\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in best_neg_labels]:\n",
    "        tick_label.set_color(\"blue\")\n",
    "\n",
    "for tick_label in g.axes.get_xticklabels():\n",
    "    if tick_label.get_text() == 'Total Frequency':\n",
    "        tick_label.set_color(\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_cutoff = .5\n",
    "\n",
    "# get the expected distributions of each message\n",
    "expected_counts = messages.mean(axis=0)\n",
    "\n",
    "entropies = []\n",
    "for idx in index:\n",
    "    # get the distribution per task\n",
    "    actual_counts = messages[log['item'] == idx].mean(axis=0)\n",
    "    relative_entropy = [\n",
    "        entropy(\n",
    "            [actual_counts.loc[msg], 1 - actual_counts.loc[msg]],\n",
    "            [expected_counts.loc[msg], 1 - expected_counts.loc[msg]],\n",
    "            base=2\n",
    "        )\n",
    "            for msg in messages.columns\n",
    "    ]\n",
    "    entropies.append(relative_entropy)\n",
    "\n",
    "# combine into a dataframe\n",
    "entropies = pd.DataFrame(\n",
    "    np.vstack(entropies),\n",
    "    index=[item.loc[i]['name'] for i in index],\n",
    "    columns=messages.columns\n",
    ").T\n",
    "\n",
    "entropies[supports < min_support] = np.nan\n",
    "\n",
    "# calculate the total frequencies for each message\n",
    "entropies['Total Frequency'] = messages.mean(axis=0)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(15,8)})\n",
    "g = sns.heatmap(\n",
    "    entropies.loc[filtered_index],  # sort and pick by mean entropy\n",
    "    vmin=0, vmax=entropy_cutoff,\n",
    "    yticklabels=[feature_descriptions[idx][:max_label_len] for idx in filtered],  # shorten the descriptions\n",
    "    mask=frequencies.loc[filtered_index].isnull(),\n",
    "    cmap=sns.cm.rocket_r\n",
    ").set_title(f'Relative Entropy for Individual Tasks vs In General (Cutoff at {entropy_cutoff}) With Min Support of {min_support}.')\n",
    "\n",
    "for tick_label in g.axes.get_yticklabels():\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in most_frequent_labels]:\n",
    "        tick_label.set_color(\"green\")\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in best_pos_labels]:\n",
    "        tick_label.set_color(\"red\")\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in best_neg_labels]:\n",
    "        tick_label.set_color(\"blue\")\n",
    "\n",
    "for tick_label in g.axes.get_xticklabels():\n",
    "    if tick_label.get_text() == 'Total Frequency':\n",
    "        tick_label.set_color(\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "correlations = []\n",
    "for idx in index:\n",
    "    incorrect = log[log['item'] == idx]['correct']\n",
    "    correlations.append(messages[log['item'] == idx].apply(lambda x: matthews_corrcoef(x, incorrect), axis=0))\n",
    "\n",
    "correlations = pd.DataFrame(\n",
    "    np.vstack(correlations),\n",
    "    index=[item.loc[i]['name'] for i in index],\n",
    "    columns=messages.columns\n",
    ").T\n",
    "\n",
    "correlations[supports < min_support] = np.nan\n",
    "\n",
    "# calculate the total frequencies for each message\n",
    "correlations['Total Frequency'] = messages.mean(axis=0)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(15,8)})\n",
    "g = sns.heatmap(\n",
    "    correlations.loc[filtered_index],  # sort and pick by mean entropy\n",
    "    vmin=-1, vmax=1,\n",
    "    yticklabels=[feature_descriptions[idx][:max_label_len] for idx in filtered],  # shorten the descriptions\n",
    "    mask=correlations.loc[filtered_index].isnull(),\n",
    "    cmap=sns.diverging_palette(230, 20, as_cmap=True)\n",
    ").set_title(f'MCC With Min Support of {min_support}.')\n",
    "\n",
    "for tick_label in g.axes.get_yticklabels():\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in most_frequent_labels]:\n",
    "        tick_label.set_color(\"green\")\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in best_pos_labels]:\n",
    "        tick_label.set_color(\"red\")\n",
    "    if tick_label.get_text() in [feature_descriptions[idx][:max_label_len] for idx in best_neg_labels]:\n",
    "        tick_label.set_color(\"blue\")\n",
    "\n",
    "for tick_label in g.axes.get_xticklabels():\n",
    "    if tick_label.get_text() == 'Total Frequency':\n",
    "        tick_label.set_color(\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_task('Trojkový foobar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log[item == 'Sedmimílové boty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_submission_for_messages('e228', idx=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
