{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/')\n",
    "item = pd.read_csv(data_path / 'cached_item.csv', index_col=0)\n",
    "\n",
    "# load from cache\n",
    "log = pd.read_csv(data_path / 'dataset.csv')\n",
    "log['time'] = pd.to_datetime(log['time'])\n",
    "log['linter_messages'] = log['linter_messages'].apply(lambda x: np.array(eval(x)))\n",
    "log.set_index('time', inplace=True)\n",
    "\n",
    "feature_descriptions = json.load(open(Path(data_path / 'edulint' / 'features.json'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task profiles\n",
    "from src.linter_profile import task_profile\n",
    "\n",
    "item = pd.concat([\n",
    "    item,\n",
    "    pd.DataFrame({'name': 'unknown', 'solution': 'pass'}, index=[12]),\n",
    "    pd.DataFrame({'name': 'unknown', 'solution': 'pass'}, index=[118]),\n",
    "\n",
    "])\n",
    "\n",
    "profiles = []\n",
    "means = []\n",
    "for task_id in item.index:\n",
    "    history = log['linter_messages'][log['item'] == task_id]\n",
    "    if len(history) == 0:\n",
    "        profiles.append(np.zeros(log['linter_messages'].iloc[0].shape[0]))\n",
    "        means.append(np.zeros(log['linter_messages'].iloc[0].shape[0]))\n",
    "    else:\n",
    "        profiles.append(task_profile(np.vstack(history)))\n",
    "        means.append(history.mean(axis=0))\n",
    "item['profile'] = profiles\n",
    "item['mean'] = means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user profiles\n",
    "from src.linter_profile import freq_profile\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "user_profiles = True\n",
    "euclidean_distance = True\n",
    "linear_model = True\n",
    "subtract_task = True\n",
    "only_last_profile = True\n",
    "cluster_profiles = True\n",
    "\n",
    "result = []\n",
    "for user_id in set(log['user']):\n",
    "    user_history = log[log['user'] == user_id].sort_values('time')\n",
    "\n",
    "    user_history['final'] = np.append(user_history['item'][:-1].values != user_history['item'][1:].values, True)\n",
    "    user_history['first'] = [True] + [False] * (len(user_history) - 1)\n",
    "\n",
    "    user_history['norm_messages'] = user_history['linter_messages'].apply(lambda x: normalize(x.reshape(1, -1)))\n",
    "\n",
    "    if subtract_task:\n",
    "        user_history['freq_profile'] = freq_profile(np.vstack(user_history['linter_messages']), np.vstack(item['mean'][user_history['item']])).tolist()\n",
    "    else:\n",
    "        user_history['freq_profile'] = freq_profile(np.vstack(user_history['linter_messages'])).tolist()\n",
    "\n",
    "    result.append(user_history)\n",
    "\n",
    "new_log = pd.concat(result)\n",
    "\n",
    "if linear_model:\n",
    "    X, y = np.vstack(new_log['freq_profile']), np.vstack(new_log['linter_messages'])\n",
    "    model = Ridge().fit(X, y)\n",
    "    new_log['freq_profile'] = model.predict(X).tolist()\n",
    "\n",
    "if euclidean_distance:\n",
    "    new_log['dist_from_profile'] = [euclidean(profile, model.predict(actual) if linear_model else actual) for i, (profile, actual) in new_log[['freq_profile', 'norm_messages']].iterrows()]\n",
    "else:\n",
    "    new_log['dist_from_profile'] = [cosine(profile, model.predict(actual) if linear_model else actual) for i, (profile, actual) in new_log[['freq_profile', 'norm_messages']].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "if only_last_profile:\n",
    "    filtered_log = new_log[new_log['final'] == True]\n",
    "else:\n",
    "    filtered_log = new_log[new_log['first'] == False]\n",
    "\n",
    "if user_profiles:\n",
    "    profiles = np.vstack(filtered_log['freq_profile'])\n",
    "else:\n",
    "    profiles = np.vstack(item['profile'])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "reducer.fit(profiles)\n",
    "embedding = reducer.transform(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "if cluster_profiles:\n",
    "    target = profiles\n",
    "else:\n",
    "    target = embedding\n",
    "\n",
    "scores = []\n",
    "best_score = -2\n",
    "best_k = 3\n",
    "kmeans = None\n",
    "for n_clusters in tqdm(range(3, 20)):\n",
    "    new = KMeans(n_clusters=n_clusters, n_init='auto').fit(target)\n",
    "    score = silhouette_score(target, new.predict(target), random_state=42, sample_size=25000)\n",
    "    scores.append(score)\n",
    "    print(np.round(score, 2), end='     ')\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = n_clusters\n",
    "        kmeans = new\n",
    "        \n",
    "labels = kmeans.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_profiles:\n",
    "    centroids = reducer.transform(kmeans.cluster_centers_)\n",
    "else:\n",
    "    centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(x=embedding[:, 0], y=embedding[:, 1], color=labels.astype(str), text=range(embedding.shape[0]))\n",
    "fig.add_trace(px.scatter(x=centroids[:, 0], y=centroids[:, 1], size=np.zeros(centroids.shape[0]) + 1, opacity=.5).data[0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = list(set(filtered_log['user']))[300]\n",
    "\n",
    "labels = kmeans.fit_predict(embedding)\n",
    "px.scatter(\n",
    "    x=embedding[:, 0],\n",
    "    y=embedding[:, 1],\n",
    "    color=(filtered_log['user'] == user).astype(str),\n",
    "    opacity=.5,\n",
    "    size=((filtered_log['user'] == user) * 5 + 1),\n",
    "    text=range(embedding.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(np.vstack(filtered_log['freq_profile'][[10532, 8598, 5492, 9655]]).T)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "user_id = filtered_log['user'].iloc[2170] # filtered_log['user'].iloc[2170]\n",
    "user_history = new_log[new_log['user'] == user_id]\n",
    "session_breakpoints = np.nonzero((user_history.index[1:] - user_history.index[:-1]) > pd.Timedelta(1, 'h'))[0].tolist()\n",
    "\n",
    "fig = make_subplots(rows=math.ceil((len(session_breakpoints) + 1) / 4), cols=4)\n",
    "\n",
    "start = 0\n",
    "for i, end in enumerate(session_breakpoints + [len(user_history)]):\n",
    "    session = user_history[start:end + 1]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=session.index,\n",
    "            y=session['dist_from_profile'],\n",
    "            text='task id ' + session['item'].astype(str),\n",
    "            mode='lines+markers',\n",
    "            marker=dict(\n",
    "                color=session['correct'].apply(lambda x: 'green' if x else 'red'),\n",
    "                symbol=session['final'].apply(lambda x: 'x' if x else 'circle'),\n",
    "                size=10\n",
    "            ),\n",
    "        ),\n",
    "        col=i % 4 + 1, row=i // 4 + 1\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0,r=0,b=0,t=40),\n",
    "        showlegend=False,\n",
    "        title=f'Sessions of user id {user_id}'\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        tickformat=\"%H:%M<br>%d-%m\"\n",
    "    )\n",
    "    start = end + 1\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log[new_log['first'] == False].sort_values('dist_from_profile', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_log[(new_log['user'] == 18489457) & (new_log['item'] == 39)]['answer'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_log[(new_log['user'] == 28707279) & (new_log['item'] == 73)]['answer'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_log[(new_log['user'] == 28700003) & (new_log['item'] == 39)]['answer'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user profiles\n",
    "from src.linter_profile import freq_profile\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "user_profiles = True\n",
    "euclidean_distance = True\n",
    "linear_model = False\n",
    "subtract_task = True\n",
    "only_last_profile = False\n",
    "\n",
    "result = []\n",
    "for user_id in set(log['user']):\n",
    "    user_history = log[log['user'] == user_id].sort_values('time')\n",
    "\n",
    "    user_history['final'] = np.append(user_history['item'][:-1].values != user_history['item'][1:].values, True)\n",
    "    user_history['first'] = [True] + [False] * (len(user_history) - 1)\n",
    "\n",
    "    user_history['norm_messages'] = user_history['linter_messages'].apply(lambda x: normalize(x.reshape(1, -1)))\n",
    "\n",
    "    if subtract_task:\n",
    "        user_history['freq_profile'] = freq_profile(np.vstack(user_history['linter_messages']), np.vstack(item['mean'][user_history['item']])).tolist()\n",
    "    else:\n",
    "        user_history['freq_profile'] = freq_profile(np.vstack(user_history['linter_messages'])).tolist()\n",
    "\n",
    "    result.append(user_history)\n",
    "\n",
    "new_log = pd.concat(result)\n",
    "\n",
    "target = 'norm_messages'\n",
    "\n",
    "if linear_model:\n",
    "    target = 'linter_messages'\n",
    "    X, y = np.vstack(new_log['freq_profile']), np.vstack(new_log['linter_messages'])\n",
    "    model = Ridge().fit(X, y)\n",
    "    new_log['freq_profile'] = model.predict(X).tolist()\n",
    "\n",
    "if euclidean_distance:\n",
    "    new_log['dist_from_profile'] = [euclidean(profile, actual) for i, (profile, actual) in new_log[['freq_profile', target]].iterrows()]\n",
    "else:\n",
    "    new_log['dist_from_profile'] = [cosine(profile, actual) for i, (profile, actual) in new_log[['freq_profile', target]].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.vstack(new_log['freq_profile']), np.vstack(new_log['linter_messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge().fit(X, y)\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "predictions = X # model.predict(X) / X\n",
    "\n",
    "correlations = []\n",
    "pvalues = []\n",
    "for dim in range(y.shape[1]):\n",
    "    cor, p = pearsonr(predictions[:, dim], y[:, dim])\n",
    "    correlations.append(cor)\n",
    "    pvalues.append(p)\n",
    "fig = px.bar(correlations, text=np.round(np.array(pvalues), 2))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.coef_) # target x feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(pd.DataFrame(X).corr(), zmin=-1, zmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(pd.DataFrame(y).corr(), zmin=-1, zmax=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
