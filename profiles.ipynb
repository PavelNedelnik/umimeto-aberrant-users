{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/')\n",
    "item = pd.read_csv(data_path / 'cached_item.csv', index_col=0)\n",
    "\n",
    "item = pd.concat([\n",
    "    item,\n",
    "    *[pd.DataFrame({'name': f'unknown_{i}', 'solution': 'pass'}, index=[idx]) for i, idx in enumerate([12, 118, 142, 143, 144, 145, 146])]\n",
    "])\n",
    "\n",
    "# load from cache\n",
    "log = pd.read_csv(data_path / 'dataset.csv')\n",
    "log['time'] = pd.to_datetime(log['time'])\n",
    "log['linter_messages'] = log['linter_messages'].apply(lambda x: np.array(eval(x)))\n",
    "\n",
    "feature_descriptions = json.load(open(Path(data_path / 'edulint' / 'features.json'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## naive model\n",
    "log['distance'] = log['linter_messages'].apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 10\n",
    "\n",
    "values, counts = np.unique(log[log['distance'] < cutoff]['distance'], return_counts=True)\n",
    "\n",
    "fig = px.bar(x=values.tolist() + [cutoff], y=counts.tolist() + [(log['distance'] > cutoff).sum()], title='Naive detector - submissions')\n",
    "fig.update_xaxes(\n",
    "    tickmode = 'array',\n",
    "    tickvals = values.tolist() + [cutoff],\n",
    "    ticktext = list(map(str, values)) + [f'>= {cutoff}']\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Distance from profile\", yaxis_title=\"# submissions\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_to_string(idx, log, item):\n",
    "    # TODO maybe print side by side\n",
    "    submission = log.loc[idx]\n",
    "    task = item.iloc[submission['item']]\n",
    "\n",
    "    return                                                                                          \\\n",
    "        f\"SUBMISSION: by user: {submission['user']} of task: {submission['item']}-{task['name']}\" + \\\n",
    "        '\\n' + \"-\" * 50 + '\\n'                                                                      \\\n",
    "        f\"DISTANCE:\\n {submission['distance']}\" +                                                   \\\n",
    "        '\\n' + \"-\" * 50 + '\\n'                                                                      \\\n",
    "        f\"INSTRUCTIONS:\\n {task['instructions']}\" +                                                 \\\n",
    "        '\\n' + \"-\" * 50 + '\\n'                                                                      \\\n",
    "        f\"SOLUTION:\\n {task['solution']}\" +                                                         \\\n",
    "        '\\n' + \"-\" * 50 + '\\n'                                                                      \\\n",
    "        f\"ANSWER:\\n {submission['answer']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submissions with most mistakes\n",
    "for idx in log.sort_values(by='distance', ascending=False).index[:5]:\n",
    "    print(submission_to_string(idx, log, item))\n",
    "    print('\\n' * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task with most mistakes\n",
    "\n",
    "mistake_counts = log.groupby('item')['distance'].mean().sort_values(ascending=False)\n",
    "mistake_counts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=[item['name'].iloc[idx] for idx in mistake_counts.index], y=mistake_counts.values, title='Average number of messages per submission for each task')\n",
    "fig.update_layout(\n",
    "    yaxis_title=\"Average number of messages\", xaxis_title=\"\"\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in mistake_counts.index:\n",
    "    try:\n",
    "        print(item['name'].iloc[idx])\n",
    "    except:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 128\n",
    "print(item.iloc[idx]['name'])\n",
    "print(item.iloc[idx]['instructions'])\n",
    "print(item.iloc[idx]['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions[0] = 'c0103_snake_case_naming_style'\n",
    "feature_descriptions[24] = 'r1705_unnecessary_elif_after_return'\n",
    "feature_descriptions[20] = 'f841_unused_local_variable'\n",
    "cutoff = 0.15\n",
    "counts = dict(zip(feature_descriptions, log[log['item'] == idx]['linter_messages'].mean()))\n",
    "counts = {label:value for label, value in counts.items() if value >= cutoff}\n",
    "counts = dict(sorted(counts.items(), reverse=True, key=lambda x: x[1]))\n",
    "fig = px.bar(x=counts.keys(), y=counts.values(), title=f'Naive detector - task {idx} profile')\n",
    "fig.update_layout(\n",
    "    yaxis_title=\"Average occurance count\", xaxis_title=\"\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user with most mistakes\n",
    "\n",
    "log.groupby('user')['distance'].mean().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(log.groupby('user')['distance'].mean(), nbins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "user_id = 18379796                       \n",
    "user_history = log[log['user'] == user_id].copy()\n",
    "user_history['final'] = np.append(user_history['item'][:-1].values != user_history['item'][1:].values, True)\n",
    "session_breakpoints = np.nonzero((user_history['time'][1:] - user_history['time'][:-1]) > pd.Timedelta(1, 'h'))[0].tolist()\n",
    "\n",
    "fig = make_subplots(rows=math.ceil((len(session_breakpoints) + 1) / 4), cols=4)\n",
    "\n",
    "start = 0\n",
    "for i, end in enumerate(session_breakpoints + [len(user_history)]):\n",
    "    session = user_history[start:end + 1]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=session.index,\n",
    "            y=session['distance'],\n",
    "            text='task id ' + session['item'].astype(str),\n",
    "            mode='lines+markers',\n",
    "            marker=dict(\n",
    "                color=session['correct'].apply(lambda x: 'green' if x else 'red'),\n",
    "                symbol=session['final'].apply(lambda x: 'x' if x else 'circle'),\n",
    "                size=10\n",
    "            ),\n",
    "        ),\n",
    "        col=i % 4 + 1, row=i // 4 + 1\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0,r=0,b=0,t=40),\n",
    "        showlegend=False,\n",
    "        title=f'Sessions of user id {user_id}'\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        tickformat=\"%H:%M<br>%d-%m\"\n",
    "    )\n",
    "    start = end + 1\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.15\n",
    "counts = dict(zip(feature_descriptions, log[log['user'] == user_id]['linter_messages'].mean()))\n",
    "counts = {label:value for label, value in counts.items() if value >= cutoff}\n",
    "counts = dict(sorted(counts.items(), reverse=True, key=lambda x: x[1]))\n",
    "fig = px.bar(x=counts.keys(), y=counts.values(), title=f'Naive detector - user {user_id} profile')\n",
    "fig.update_layout(\n",
    "    yaxis_title=\"Average occurance count\", xaxis_title=\"\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.linter_profile import make_task_means, make_task_profiles\n",
    "\n",
    "item['msg_mean'] = make_task_means(item, log)\n",
    "item['profile'] = make_task_profiles(item, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.linter_profile import make_user_profiles\n",
    "\n",
    "log['profile'] = make_user_profiles(log, task_means=item['msg_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import DistanceModel\n",
    "\n",
    "log['distance'] = DistanceModel().fit_predict(log['profile'], log['linter_messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "messages = normalize(np.vstack(log['linter_messages']), 'l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_not_first(log):\n",
    "    return log[log.groupby('user')['time'].transform('idxmin') != log.index]\n",
    "\n",
    "\n",
    "def only_last(log):\n",
    "    return log.loc[log.groupby('user')['time'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "profiles = np.vstack(item['profile'])\n",
    "reducer = umap.UMAP()\n",
    "reducer.fit(profiles)\n",
    "embedding = reducer.transform(profiles)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "target = embedding\n",
    "\n",
    "scores = []\n",
    "best_score = -2\n",
    "best_k = 3\n",
    "kmeans = None\n",
    "for n_clusters in tqdm(range(3, 20)):\n",
    "    new = KMeans(n_clusters=n_clusters, n_init='auto').fit(target)\n",
    "    score = silhouette_score(target, new.predict(target), random_state=42, sample_size=25000)\n",
    "    scores.append(score)\n",
    "    print(np.round(score, 2), end='     ')\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = n_clusters\n",
    "        kmeans = new\n",
    "        \n",
    "labels = kmeans.predict(target)\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(x=embedding[:, 0], y=embedding[:, 1], color=labels.astype(str), hover_name=item.index)\n",
    "fig.add_trace(px.scatter(x=centroids[:, 0], y=centroids[:, 1], size=np.zeros(centroids.shape[0]) + 1, opacity=.5).data[0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 9\n",
    "print(item.loc[num]['name'])\n",
    "print(item.loc[num]['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 19\n",
    "print(item.loc[num]['name'])\n",
    "print(item.loc[num]['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "if only_last_profile:\n",
    "    filtered_log = new_log[new_log['final'] == True]\n",
    "else:\n",
    "    filtered_log = new_log[new_log['first'] == False]\n",
    "\n",
    "if user_profiles:\n",
    "    profiles = np.vstack(filtered_log['freq_profile'])\n",
    "else:\n",
    "    profiles = np.vstack(item['profile'])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "reducer.fit(profiles)\n",
    "embedding = reducer.transform(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "if cluster_profiles:\n",
    "    target = profiles\n",
    "else:\n",
    "    target = embedding\n",
    "\n",
    "scores = []\n",
    "best_score = -2\n",
    "best_k = 3\n",
    "kmeans = None\n",
    "for n_clusters in tqdm(range(3, 20)):\n",
    "    new = KMeans(n_clusters=n_clusters, n_init='auto').fit(target)\n",
    "    score = silhouette_score(target, new.predict(target), random_state=42, sample_size=25000)\n",
    "    scores.append(score)\n",
    "    print(np.round(score, 2), end='     ')\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = n_clusters\n",
    "        kmeans = new\n",
    "        \n",
    "labels = kmeans.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_profiles:\n",
    "    centroids = reducer.transform(kmeans.cluster_centers_)\n",
    "else:\n",
    "    centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(x=embedding[:, 0], y=embedding[:, 1], color=labels.astype(str), text=range(embedding.shape[0]))\n",
    "fig.add_trace(px.scatter(x=centroids[:, 0], y=centroids[:, 1], size=np.zeros(centroids.shape[0]) + 1, opacity=.5).data[0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = list(set(filtered_log['user']))[300]\n",
    "\n",
    "labels = kmeans.fit_predict(embedding)\n",
    "px.scatter(\n",
    "    x=embedding[:, 0],\n",
    "    y=embedding[:, 1],\n",
    "    color=(filtered_log['user'] == user).astype(str),\n",
    "    opacity=.5,\n",
    "    size=((filtered_log['user'] == user) * 5 + 1),\n",
    "    text=range(embedding.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(np.vstack(filtered_log['freq_profile'][[10532, 8598, 5492, 9655]]).T)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "user_id = 14723775 # filtered_log['user'].iloc[2170]\n",
    "user_history = new_log[new_log['user'] == user_id]\n",
    "session_breakpoints = np.nonzero((user_history.index[1:] - user_history.index[:-1]) > pd.Timedelta(1, 'h'))[0].tolist()\n",
    "\n",
    "fig = make_subplots(rows=math.ceil((len(session_breakpoints) + 1) / 4), cols=4)\n",
    "\n",
    "start = 0\n",
    "for i, end in enumerate(session_breakpoints + [len(user_history)]):\n",
    "    session = user_history[start:end + 1]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=session.index,\n",
    "            y=session['dist_from_profile'],\n",
    "            text='task id ' + session['item'].astype(str),\n",
    "            mode='lines+markers',\n",
    "            marker=dict(\n",
    "                color=session['correct'].apply(lambda x: 'green' if x else 'red'),\n",
    "                symbol=session['final'].apply(lambda x: 'x' if x else 'circle'),\n",
    "                size=10\n",
    "            ),\n",
    "        ),\n",
    "        col=i % 4 + 1, row=i // 4 + 1\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0,r=0,b=0,t=40),\n",
    "        showlegend=False,\n",
    "        title=f'Sessions of user id {user_id}'\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        tickformat=\"%H:%M<br>%d-%m\"\n",
    "    )\n",
    "    start = end + 1\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log[new_log['first'] == False].sort_values('dist_from_profile', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, submission in new_log[(new_log['user'] == 14723775) & (new_log['item'] == 66)].iterrows():\n",
    "    print(submission['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, submission in new_log[(new_log['user'] == 52565485) & (new_log['item'] == 66)].iterrows():\n",
    "    print(submission['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, submission in new_log[(new_log['user'] == 41811185) & (new_log['item'] == 74)].iterrows():\n",
    "    print(submission['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, submission in new_log[(new_log['user'] == 39127736) & (new_log['item'] == 39)].iterrows():\n",
    "    print(submission['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user profiles\n",
    "from src.linter_profile import freq_profile\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "user_profiles = True\n",
    "euclidean_distance = True\n",
    "linear_model = False\n",
    "subtract_task = False\n",
    "only_last_profile = False\n",
    "\n",
    "result = []\n",
    "for user_id in set(log['user']):\n",
    "    user_history = log[log['user'] == user_id].sort_values('time')\n",
    "\n",
    "    user_history['final'] = np.append(user_history['item'][:-1].values != user_history['item'][1:].values, True)\n",
    "    user_history['first'] = [True] + [False] * (len(user_history) - 1)\n",
    "\n",
    "    user_history['norm_messages'] = user_history['linter_messages'].apply(lambda x: normalize(x.reshape(1, -1)))\n",
    "\n",
    "    if subtract_task:\n",
    "        user_history['freq_profile'] = freq_profile(np.vstack(user_history['linter_messages']), np.vstack(item['mean'][user_history['item']])).tolist()\n",
    "    else:\n",
    "        user_history['freq_profile'] = freq_profile(np.vstack(user_history['linter_messages'])).tolist()\n",
    "\n",
    "    result.append(user_history)\n",
    "\n",
    "new_log = pd.concat(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.vstack(new_log['freq_profile']), np.vstack(new_log['linter_messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge().fit(X, y)\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "predictions = X # model.predict(X) / X\n",
    "\n",
    "correlations = []\n",
    "pvalues = []\n",
    "for dim in range(y.shape[1]):\n",
    "    cor, p = pearsonr(predictions[:, dim], y[:, dim])\n",
    "    correlations.append(cor)\n",
    "    pvalues.append(p)\n",
    "fig = px.bar(correlations, text=np.round(np.array(pvalues), 2))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(pd.DataFrame(X).corr(), zmin=-1, zmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(pd.DataFrame(y).corr(), zmin=-1, zmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(z=model.coef_, text=[[f'{x} -> {y}' for x in feature_descriptions] for y in feature_descriptions]))\n",
    "fig.update_layout(xaxis=dict(scaleanchor='y',constrain='domain'))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
