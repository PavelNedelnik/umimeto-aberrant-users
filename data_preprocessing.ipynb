{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.load_scripts import load_log, load_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/')\n",
    "\n",
    "retrain = False\n",
    "\n",
    "if retrain:\n",
    "    item = load_item(data_path)\n",
    "    log = load_log(data_path)\n",
    "    #item.to_csv(data_path / 'cached_item.csv')\n",
    "    #log.to_csv(data_path / 'cached_log.csv')\n",
    "else:\n",
    "    # load from cache\n",
    "    item = pd.read_csv(data_path / 'cached_item.csv', index_col=0)\n",
    "\n",
    "    # load from cache\n",
    "    log = pd.read_csv(data_path / 'cached_log.csv')\n",
    "    log['time'] = pd.to_datetime(log['time'])\n",
    "    log.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log = []\n",
    "counts = log['user'].value_counts()\n",
    "\n",
    "for file_path in (data_path / 'edulint').glob(\"*.json\"):\n",
    "    start, end = file_path.stem.split('_')[2].split('-')\n",
    "    start, end = int(start), int(end)\n",
    "    selected_counts = counts[(counts >= start) & (counts < end)]\n",
    "    log_slice = pd.DataFrame(log.query('user in @selected_counts.index'))\n",
    "    log_slice['linter_messages'] = [' '.join(alist) for alist in json.load(open(file_path, 'r'))]\n",
    "    new_log.append(log_slice)\n",
    "\n",
    "new_log = pd.concat(new_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0.005)\n",
    "vectors = vectorizer.fit_transform(new_log['linter_messages'])\n",
    "\n",
    "new_log['linter_messages'] = list(map(np.array, vectors.toarray().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path('data/edulint/results.txt'), 'r') as f:\n",
    "    results = f.read().lower()\n",
    "    \n",
    "feature_descriptions = []\n",
    "for feature_name in vectorizer.get_feature_names_out():\n",
    "    begin = results.find(feature_name)\n",
    "    feature_descriptions.append(results[begin:results.find('_\"', begin)])\n",
    "\n",
    "json.dump(feature_descriptions, open(Path('data/edulint/features.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log['linter_messages'] = new_log['linter_messages'].apply(lambda x: x.tolist())\n",
    "new_log.to_csv(data_path / 'dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
