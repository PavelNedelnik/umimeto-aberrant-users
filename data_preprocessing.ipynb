{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.load_scripts import load_log, load_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/')\n",
    "\n",
    "retrain = False\n",
    "\n",
    "if retrain:\n",
    "    item = load_item(data_path)\n",
    "    log = load_log(data_path, data_path / 'edulint')\n",
    "\n",
    "    item.to_csv(data_path / 'cached_item.csv')\n",
    "    log.to_csv(data_path / 'cached_log.csv')\n",
    "else:\n",
    "    item = pd.read_csv(data_path / 'cached_item.csv', index_col=0)\n",
    "    log = pd.read_csv(data_path / 'cached_log.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0.005)\n",
    "vectors = vectorizer.fit_transform(log['linter_messages'])\n",
    "tfidf = TfidfTransformer().fit_transform(vectors)\n",
    "\n",
    "log['linter_messages'] = list(map(np.array, vectors.toarray().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path('data/edulint/results.txt'), 'r') as f:\n",
    "    results = f.read().lower()\n",
    "    \n",
    "feature_descriptions = []\n",
    "for feature_name in vectorizer.get_feature_names_out():\n",
    "    begin = results.find(feature_name)\n",
    "    feature_descriptions.append(results[begin:results.find('_\"', begin)])\n",
    "\n",
    "json.dump(feature_descriptions, open(Path('data/edulint/features.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.iloc[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_in_out_class_distances(log: pd.DataFrame, target: str):\n",
    "    in_classes = []\n",
    "    out_classes = []\n",
    "    for cls in np.unique(log[target]):\n",
    "        in_classes.append(log[log[target] == cls]['distance_from_profile'].mean())\n",
    "        out_classes.append(log[log[target] != cls]['distance_from_profile'].mean())\n",
    "    return np.asarray(in_classes).mean(), np.asarray(out_classes).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.linter_profile import MeanTaskProfiler, MeanNormTaskProfiler, NormSumTaskProfiler, NormForgetUserProfiler\n",
    "from src.model import DistanceModel\n",
    "\n",
    "dim = len(feature_descriptions)\n",
    "profilers = [NormForgetUserProfiler(dim)]\n",
    "model = DistanceModel('euclidean', 'l2')\n",
    "for profiler in profilers:\n",
    "    log['profile'] = profiler.build_profiles(log)\n",
    "    log['distance_from_profile'] = model.calculate_distances(log['profile'], log['linter_messages'])\n",
    "    print(mean_in_out_class_distances(log, 'user'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['task_profile'] = MeanNormTaskProfiler(dim).build_profiles(log)\n",
    "log['user_profile'] = NormForgetUserProfiler(dim).build_profiles(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = np.hstack([np.vstack(log['task_profile']), np.vstack(log['user_profile'])])\n",
    "# X = np.vstack(log['task_profile'])\n",
    "# X = np.vstack(log['user_profile'])\n",
    "y = np.vstack(log['linter_messages'])\n",
    "reg = RandomForestRegressor().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "results = []\n",
    "for i in range(y.shape[1]):\n",
    "    results.append(pearsonr(X[:, i], y[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([s for s, p in results]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.sort_values(by='distance_from_profile', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
